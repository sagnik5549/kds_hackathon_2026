# ğŸ“š Backstory Consistency Verification System

A retrieval-based NLP system that verifies whether a given backstory claim is **consistent or contradictory** with a novel, using semantic embeddings and evidence retrieval.

---

## ğŸ” Problem Overview

Given:
- A **backstory claim**
- A **primary text (novel)**

The system:
1. Retrieves the most relevant excerpts from the novel
2. Scores semantic similarity
3. Decides **Consistency (1) / Contradiction (0)**
4. Returns **verbatim textual evidence**

---

## ğŸ§  Approach

- **Chunking**: Overlapping word-based chunks
- **Embedding**: Sentence-Transformers (`all-MiniLM-L6-v2`)
- **Retrieval**: Cosine similarity (top-k)
- **Decision Rule**: Threshold-based verification
- **Explainability**: Top-k excerpts returned as evidence

---

## ğŸ“ Project Structure
backstory-consistency-kds2026/<br>
â”‚<br>
â”œâ”€â”€ data/<br>
â”‚   â”œâ”€â”€ books/<br>
â”‚   â”‚   â”œâ”€â”€ The Count of Monte Cristo.txt<br>
â”‚   â”‚   â””â”€â”€ In Search of the Castaways.txt<br>
â”‚   â”‚       **â†’ Primary novels used as factual ground truth**<br>
â”‚   â”‚<br>
â”‚   â”œâ”€â”€ train.csv<br>
â”‚   â”‚   **â†’ Labeled backstory claims used for threshold tuning<br>
â”‚   â”‚     Columns: [id, content, book_name, label]**<br>
â”‚   â”‚<br>
â”‚   â””â”€â”€ test.csv<br>
â”‚       **â†’ Unlabeled claims for final evaluation**<br>
â”‚<br>
â”œâ”€â”€ src/<br>
â”‚   â”œâ”€â”€ chunking.py<br>
â”‚   â”‚   **â†’ Splits full novels into overlapping word chunks**<br>
â”‚   â”‚<br>
â”‚   â”œâ”€â”€ embeddings.py<br>
â”‚   â”‚   **â†’ Generates semantic embeddings using Sentence-Transformers**<br>
â”‚   â”‚<br>
â”‚   â”œâ”€â”€ retrieval.py<br>
â”‚   â”‚   **â†’ Retrieves top-k most relevant chunks using cosine similarity**<br>
â”‚   â”‚<br>
â”‚   â”œâ”€â”€ consistency.py<br>
â”‚   â”‚   **â†’ Core logic:<br>
â”‚   â”‚     - Compares backstory claim with retrieved chunks<br>
â”‚   â”‚     - Applies threshold to decide consistency / contradiction**<br>
â”‚   â”‚<br>
â”‚   â””â”€â”€ io_utils.py<br>
â”‚       **â†’ Utility functions for loading books by name** <br>
â”‚
â”œâ”€â”€ scripts/<br>
â”‚   â”œâ”€â”€ run_train_eval.py<br>
â”‚   â”‚   **â†’ Uses train.csv to:<br>
â”‚   â”‚     - Run consistency checks<br>
â”‚   â”‚     - Sweep similarity thresholds<br>
â”‚   â”‚     - Select best threshold based on accuracy**<br>
â”‚   â”‚<br>
â”‚   â””â”€â”€ run_test.py<br>
â”‚       **â†’ Runs final consistency predictions on test.csv<br>
â”‚         â†’ Outputs decisions and supporting evidence**<br>
â”‚<br>
â”œâ”€â”€ results/<br>
â”‚   â””â”€â”€ results.csv<br>
â”‚       **â†’ Stores generated predictions and evaluation outputs**<br>
â”‚<br>
â”œâ”€â”€ report/<br>
â”‚   â””â”€â”€ Report.pdf<br>
â”‚       **â†’ Final report / submission documents (if required)**<br>
â”‚<br>
â”œâ”€â”€ README.md<br>
â”‚   **â†’ Project documentation**<br>
â”‚<br>
â”œâ”€â”€ test_consistency.py<br>
â”‚   **â†’ Quick sanity checks for consistency decision logic**<br>
â”‚<br>
â””â”€â”€ .gitignore<br>
    **â†’ Excludes cache, environments, and generated files**<br>

